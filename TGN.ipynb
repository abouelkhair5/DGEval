{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60678bd-b470-473e-b829-619e2665c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch \n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from torch.nn import Linear\n",
    "\n",
    "from torch_geometric.datasets import JODIEDataset\n",
    "from torch_geometric.loader import TemporalDataLoader\n",
    "from torch_geometric.nn import TGNMemory, TransformerConv\n",
    "from torch_geometric.nn.models.tgn import (\n",
    "    IdentityMessage,\n",
    "    LastAggregator,\n",
    "    LastNeighborLoader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbd0499-544c-478e-97ea-d31c328dda7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0412f-9795-4660-9089-d0cdadb9fa41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87fd5ca-6ca0-4ed3-a06f-fbcffff12e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aabouelk/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA A40 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA A40 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "path = osp.join(osp.dirname(osp.abspath('')), '..', 'data', 'JODIE')\n",
    "dataset = JODIEDataset(path, name='wikipedia')\n",
    "data = dataset[0]\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34168fed-04e8-4231-8038-6959b70c622f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data, val_data, test_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_val_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m TemporalDataLoader(\n\u001b[1;32m      5\u001b[0m     train_data,\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      7\u001b[0m     neg_sampling_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m TemporalDataLoader(\n\u001b[1;32m     10\u001b[0m     val_data,\n\u001b[1;32m     11\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     12\u001b[0m     neg_sampling_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/temporal.py:273\u001b[0m, in \u001b[0;36mTemporalData.train_val_test_split\u001b[0;34m(self, val_ratio, test_ratio)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Splits the data in training, validation and test sets according to\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03mtime.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m        dataset to include in the test split. (default: :obj:`0.15`)\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m val_time, test_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mquantile(\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    271\u001b[0m     [\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m val_ratio \u001b[38;5;241m-\u001b[39m test_ratio, \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m test_ratio])\n\u001b[0;32m--> 273\u001b[0m val_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_time\u001b[49m)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m    274\u001b[0m test_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m test_time)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[:val_idx], \u001b[38;5;28mself\u001b[39m[val_idx:test_idx], \u001b[38;5;28mself\u001b[39m[test_idx:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = data.train_val_test_split(\n",
    "    val_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "train_loader = TemporalDataLoader(\n",
    "    train_data,\n",
    "    batch_size=200,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "val_loader = TemporalDataLoader(\n",
    "    val_data,\n",
    "    batch_size=200,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "test_loader = TemporalDataLoader(\n",
    "    test_data,\n",
    "    batch_size=200,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "neighbor_loader = LastNeighborLoader(data.num_nodes, size=10, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694954d4-0608-42ec-b0a5-26ef29ebac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionEmbedding(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, msg_dim, time_enc):\n",
    "        super().__init__()\n",
    "        self.time_enc = time_enc\n",
    "        edge_dim = msg_dim + time_enc.out_channels\n",
    "        self.conv = TransformerConv(in_channels, out_channels // 2, heads=2,\n",
    "                                    dropout=0.1, edge_dim=edge_dim)\n",
    "\n",
    "    def forward(self, x, last_update, edge_index, t, msg):\n",
    "        rel_t = last_update[edge_index[0]] - t\n",
    "        rel_t_enc = self.time_enc(rel_t.to(x.dtype))\n",
    "        edge_attr = torch.cat([rel_t_enc, msg], dim=-1)\n",
    "        return self.conv(x, edge_index, edge_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406294c-624f-426f-b9d8-670697f0b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.lin_src = Linear(in_channels, in_channels)\n",
    "        self.lin_dst = Linear(in_channels, in_channels)\n",
    "        self.lin_final = Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, z_src, z_dst):\n",
    "        h = self.lin_src(z_src) + self.lin_dst(z_dst)\n",
    "        h = h.relu()\n",
    "        return self.lin_final(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b93caa-49c5-4a2e-a36f-e035744359f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_dim = time_dim = embedding_dim = 100\n",
    "\n",
    "memory = TGNMemory(\n",
    "    data.num_nodes,\n",
    "    data.msg.size(-1),\n",
    "    memory_dim,\n",
    "    time_dim,\n",
    "    message_module=IdentityMessage(data.msg.size(-1), memory_dim, time_dim),\n",
    "    aggregator_module=LastAggregator(),\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171dbf9-969e-4b24-b566-17d0152a6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GraphAttentionEmbedding(\n",
    "    in_channels=memory_dim,\n",
    "    out_channels=embedding_dim,\n",
    "    msg_dim=data.msg.size(-1),\n",
    "    time_enc=memory.time_enc,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee1e0e-687b-46bc-8623-ab45744d5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_pred = LinkPredictor(in_channels=embedding_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a892e5aa-5937-4d44-8c2b-01a5e5347b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    set(memory.parameters()) | set(gnn.parameters())\n",
    "    | set(link_pred.parameters()), lr=0.0001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff383e2c-86ac-4816-a659-2beae761598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc = torch.empty(data.num_nodes, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aad4fe-f5e7-4da5-9bb9-fe1f43efbb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    memory.train()\n",
    "    gnn.train()\n",
    "    link_pred.train()\n",
    "\n",
    "    memory.reset_state()  # Start with a fresh memory.\n",
    "    neighbor_loader.reset_state()  # Start with an empty graph.\n",
    "\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "        # Get updated memory of all nodes involved in the computation.\n",
    "        z, last_update = memory(n_id)\n",
    "        z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "                data.msg[e_id].to(device))\n",
    "        pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "        neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
    "\n",
    "        loss = criterion(pos_out, torch.ones_like(pos_out))\n",
    "        loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
    "\n",
    "        # Update memory and neighbor loader with ground-truth state.\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        memory.detach()\n",
    "        total_loss += float(loss) * batch.num_events\n",
    "\n",
    "    return total_loss / train_data.num_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7a819-ad49-45a1-ad2f-07ab14224bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    memory.eval()\n",
    "    gnn.eval()\n",
    "    link_pred.eval()\n",
    "\n",
    "    torch.manual_seed(12345)  # Ensure deterministic sampling across epochs.\n",
    "\n",
    "    aps, aucs = [], []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
    "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "        z, last_update = memory(n_id)\n",
    "        z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
    "                data.msg[e_id].to(device))\n",
    "        pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
    "        neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
    "\n",
    "        y_pred = torch.cat([pos_out, neg_out], dim=0).sigmoid().cpu()\n",
    "        y_true = torch.cat(\n",
    "            [torch.ones(pos_out.size(0)),\n",
    "             torch.zeros(neg_out.size(0))], dim=0)\n",
    "\n",
    "        aps.append(average_precision_score(y_true, y_pred))\n",
    "        aucs.append(roc_auc_score(y_true, y_pred))\n",
    "\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "    return float(torch.tensor(aps).mean()), float(torch.tensor(aucs).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d490b-dad4-4143-96bf-d1497e74a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "    val_ap, val_auc = test(val_loader)\n",
    "    test_ap, test_auc = test(test_loader)\n",
    "    print(f'Val AP: {val_ap:.4f}, Val AUC: {val_auc:.4f}')\n",
    "    print(f'Test AP: {test_ap:.4f}, Test AUC: {test_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
